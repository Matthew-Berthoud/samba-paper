\section{Background \& Motivation}
\label{sec:background}

\textbf{adwait}

SAMBA builds upon a number of technologies and concepts in the cloud security space.

\subsection{Trusted Execution Environments}
A Trusted Execution Environment (TEE) is a secure area within a processor that ensures the confidentiality, integrity, and isolation of sensitive code and data.
By separating secure operations from the rest of the system, TEEs protect against both software and hardware attacks, making them essential for applications requiring high trust. 
TEEs also support remote attestation, enabling them to prove to external entities that they are running untampered code in a protected environment.
Google's Project Oak leverages TEEs and the DICE protocol to perform a "measured boot" of the Oak Restricted Kernel.
This means that each stage of the boot process measures (computes the hash of) the following stage, adding them to an attestation record.
We extend this attestation to attest between functions in SAMBA.

AMD SEV-SNP (Secure Encrypted Virtualization - Secure Nested Paging) extends the concept of TEEs to virtualized environments, particularly in cloud computing.
It encrypts each virtual machine's memory with unique hardware-managed keys, ensuring data confidentiality even if the host system or hypervisor is compromised.
SEV-SNP also protects memory integrity by preventing unauthorized modifications and enforces strong isolation between VMs.

\subsection{Function as a Service}
Function as a Service (FaaS) is a cloud computing model that enables developers to deploy and execute individual functions or pieces of code without managing the underlying infrastructure.
These functions are event-driven and run in stateless containers, automatically scaling up or down based on demand, according to the policy of the orchestrator.
FaaS eliminates the need for developers to provision and managing servers, allowing them to focus on writing code while the cloud provider handles resource allocation, availability, and execution.
Popular FaaS platforms include AWS Lambda, Google Cloud Functions, and Azure Functions.
Open and partially open source FaaS platforms discussed in this paper include OpenFaaS, OpenWhisk, and Open Function.

\subsection{Asymmetric Cryptography}
Asymmetric cryptography, also known as public key cryptography, is a cryptographic system that uses a pair of keys: a public key and a secret key.
The public key is shared openly and used for encrypting messages or verifying digital signatures, while the secret key is kept secret and used for decrypting messages or creating digital signatures.
This key pair enables secure communication without the need to share a secret key beforehand.
In SAMBA, public and secret keys are derived from the AMD SEV-SNP hardware, but are specific to each VM.

\subsection{Proxy Re-encryption}
Proxy re-encryption (PRE) is a cryptographic technique that allows transforming ciphertext encrypted under one public key into ciphertext encrypted under a different public key, without revealing the underlying plaintext or requiring access to the private keys.
This is achieved using a re-encryption token, generated by the original data owner, using their private key, and the public key of the destination user they want to re-encrypt to.
That token and the original ciphertext can be sent to the destination user who can re-encrypt the data using the token, and then decrypt it with their private key.
SAMBA applies PRE to FaaS, since auto-scaling behavior means that the original instance of a function may need to re-encrypt data to a scaled-up replica.

\subsection{Aggregate Signatures}
Aggregate signatures are a cryptographic method that combines multiple digital signatures from different signers into a single compact signature, which can be verified collectively.
This technique reduces the overall size of signatures and improves efficiency while maintaining the ability to verify that each signer endorsed their respective message.
SAMBA implements this to verify the path that function data took in a function chain.

\textbf{herwig}

\parhead{Confidential computing.}
%
\emph{Confidential computing} protects data in use by processing it within a
hardware TEE, isolating it from unauthorized access or modification.
%
This proposal focuses on the latest generation of TEEs---specifically AMD
SEV-SNP~\cite{amd-sev_snp}---which encrypts the memory of an entire guest VM to
create \emph{confidential VMs}.
%
% (the Versioned Chip Endorsement Key, or VCEK) 
A critical feature of AMD SEV-SNP (and all TEEs) is \emph{remote attestation}:
the trusted hardware measures (computes a hash of) the VM workload, and a
unique hardware key signs this initial state, producing an \emph{attestation
report}.
%
Thus, AMD serves as the root of trust, eliminating the need to trust the server
owner, while customers can retrieve the attestation report to verify that the
correct software is running within the confidential VM\@.
%
To allow an attestation to bind a runtime value, the confidential VM can
include a small amount of \emph{user data} in the signed report.
%
%
%AMD also provides certificate authority servers that can issue a VCEK
%certificate by signing the corresponding hardware key.


\parhead{Proxy re-encryption.}
%
% https://www.cs.jhu.edu/~susan/600.641/scribes/lecture17.pdf
%
\emph{Proxy re-encryption} is a cryptographic scheme that allows an untrusted
proxy to convert a ciphertext encrypted under Alice's public key into a
ciphertext that Bob can decrypt with his secret key, without learning the
underlying plaintext.
%
At a high-level, Alice and Bob construct a public \emph{re-encryption key}
$RK_{\text{Alice}\rightarrow\text{Bob}}$ that
the proxy uses to re-encrypt the ciphertext from Alice (the \emph{delegator}) to Bob
(the \emph{delegatee}).
%
In 1998, Blaze, Bleumer, \& Strauss~\cite{98-eurocrypt-proxy_cryptography}
designed the first proxy re-encryption construction based on the ElGamal
encryption system~\cite{85-toit-elgamal}.
%
Shortly thereafter, Dodis and Ivan~\cite{03-ndss-proxy_cryptography_revisited}
developed a unidirectional variant, and later Ateniese et
al.~\cite{05-ndss-improved_proxy_reencryption} applied bilinear
maps~\cite{01-crypto-ibe_weil_pairing} (and specifically BLS
signatures~\cite{03-eurocrypt-aggregate_signatures_bilinear_maps}) to develop
schemes that did not require interaction between the delegator and delegatee.
%
Since then, numerous works have explored features like multiple
re-encryptions~\cite{17-tops-fast_proxy_re_encryption} and
revocation~\cite{12-crypto-dynamic_credentials_and_delegation_for_abe}, and
security properties like chosen-ciphertext
resistance~\cite{07-ccs-cca_proxy_re_encryption} and
unlinkability of ciphertexts~\cite{19-acisp-pcs_proxy_reencryption}.


\subsection{Threat Model}
\label{sec:threat-model}

Our system has three parties: the \emph{cloud provider}, the \emph{function
providers}, and \emph{external attackers}.
%
A function chain may contain functions from multiple providers.
%
For any given function provider, the potential adversaries
are the other function providers in the chain, the cloud provider, and
external attackers.
%
The goal of an adversary is to learn the inputs or outputs of a (peer)
function, modify these inputs or outputs, or modify the sequence of functions
in the chain (e.g., to insert a function that sends data to an
adversary-controlled log).
%
A function provider can submit any function to the chain, including a
malicious function that tries to leak data or subvert the cloud
provider.
%
We assume that functions may contain bugs that unintentionally leak
data or expose the function to exploitation.
%
We assume an adversary cannot breach the security of confidential VMs; we trust
the system software in the VM, and consider side-channel attacks out-of-scope.
%
%Since the cloud provider can trivially deny service, we do not guarantee
%availability.


\subsection{Goals}
\label{sec:goals}
\textbf{NOTHING HERE}

\textbf{adwait "Overview" section}
% Overview of Approach (a nice and accessible ``English'' description of
% your approach). Don't forget a niche high-level figure. Our sample
% high-level figure is shown in Figure~\ref{fig:overview}.

% There is sometimes a background section before the overview section. In
% general, you want to try to get your high level figure somewhere between
% pages 2 and 4. It is generally bad to have a figure on the first page
% (but was unavoidable in this sample).

% You may need to move this \begin{figure} ... \end{figure} block around
% in the document to place it in a logical spot in the paper. In
% general, get the figure on the same page as the prose that refers to
% it.
% \begin{figure}[t]
%   \centering
%   \includegraphics[width=3in]{figs/overview}
%   \caption{A high-level architecture of our approach}
%   \label{fig:overview}
% \end{figure}


Our approach consists of two main goals:
\begin{enumerate}
  \item Enabling encryption between functions even in the case of auto-scaling
  \item Extending the attestation goals of Project Oak to cover multi-function workflows
\end{enumerate}

\subsection{Encryption Under Auto-scaling}

Our first goal will be achieved by implementing support for proxy re-encryption within the runtime of the VMs that get scaled by the FaaS orchestrator. The following example explains how this works.
Say function $A$ is passing data to function $B$.
If we knew for a fact that there would only be one instance of function $B$, we could use $B$'s public key to encrypt the data.
Then, when the encrypted data arrives at $B$, they could decrypt it with their private key.

Function as a Service functions add a wrinkle to this simple asymmetric encryption key encryption, due to their autoscaling behavior.
Public and secret keys are bound uniquely to individual Oak Restricted Kernel VMs.
Since only one instance of each function runs in each VM, a messsage encrypted to one replica of a function will not be readable by another replica of that same function.
We assume that all chained functions, in our example function $A$, believe they are sending data to the "original" replica of the recipient function, say $B_0$. 
When the function orchestration framework recieves this request, however, if load balancing has occured, chances are they will be disbatching that request to a replica function, some $B_i$.
Since $B_i$ can't read the message from $A$ without access to $B_0$'s secret key, re-enctyption must occur.

In our solution, the moment any replica $B_i$ is created to handle additional load, a \textit{proxy re-encryption token} request is sent to the original function, $B_0$.
The request contains some indication that it's a \textit{proxy re-encryption token} request, as well as $B_i$'s public key.
Using that $B_i$'s public key and $B_0$'s secret key, $B_0$ generates a proxy re-encryption token, with the method described in Section~\ref{sec:background}. 
That token is sent back to the orchestrator, who provides it to $B_i$ on startup.
Now, whenever the orchestrator is load balancing and wants to assign a workload to $B_i$, it can directly send ciphertext that was encrypted for $B_0$, without added overhead.
Upon recieving the data, $B_i$ can first re-encrypt it with the $B_0,B_i$ token, and then decrypt it with their ($B_i$'s) private key.

This one additional crypto operation is a necessary sacrifice to keep the efficiency gains of auto-scaling, while adding confidentiality from encryption.
We chose to perform the re-encryption step in the recipient replica $B_i$ as opposed to the orchestrator.
In theory, for each request, either of those approaches would take the same amount of time.
However, in the real context of a high-load system with more than one workload in need of allocation, offloading the additional step to the replica frees up the orchestrator to continue handling requests.


\subsection{Function Chain Attestation}

Our second goal will be achieved by implementing certificate chain validation within the function VM runtime.
The Oak Restricted Kernel already performs a "measured boot" where each stage of the VM's startup process "measures" the next, attesting to its correctness.
They do this according to the DICE protocol.
This makes it so that only Stage 0 of that process has to be trusted, as well as the hardware, since any interfering with other parts of the boot will be recorded, and recognized when verifying the measurement.

We extend this idea by creating a certificate chain, as explained in Section~\ref{sec:background}, of the callers and callees in each fucntion chain.
We extend the Oak Restricted Kernel runtime to that during the booting of a function, this chain is checked against the expected route.
From there, the current workload is hashed, signed, and added onto the chain.
The next function, or the end user will be able to verify in the same way.

\subsection{Threat Model}

There are three main parties at play in our system. The cloud provider, the function providers (users), and external attackers.
The possible adversaries for any given user are other users in the same chain of functions, the cloud provider who's hosting the user's function, and external attackers.
The goal of other users could be to pass fraudulent data into the function in question, change the order of function execution, or more generally read function input/output data they aren't authorized to read.
The goal of the cloud provider could be to boot the function in such a way that it logs all data back to them, and protecting against this is in scope.
The goal of external attackers would be similar to that of other users, but likely with less explicit baseline access to the function provider.
Our Trusted Computing Base (TCB) includes the AMD SEV-SNP hardware, and the Oak Restricted Kernel software.
We put no trust in the cloud provider, other functions in the chain, or in any centralized keystore or log.
We do assume side-channel attacks are out of scope, but preventing these while maintaining SAMBA's guarantes could be an interesting area of future research, discussed in Section~\ref{sec:discussion}.


\textbf{compilers class proposal}

This section details some necessary background on proxy re-encryption, and compiler optimizations for cryptographic operations.

\subsection{Proxy Re-encryption}
\label{sec:pre}
The basic idea of proxy re-encryption can be thought of with a simple example.
Say an employee Alice at a company is going on vacation, and wants her assistant Proxy (a normal human name) to be able to forward encrypted emails sent to her to her co-worker Bob while she's out of the office.
In the ordinary case, when Alice is not on vacation, messages will be encrypted to her using her public key, and she can decrypt them using her private key.
When Alice is on vacation, she wants Bob to be able to open the emails without giving him or Proxy access to her private key, and without Proxy being able to open the message at all.
At a high level, this can be done by Proxy "re-encrypting" the message, such that it transforms from a message which Alice's private key can decrypt, to a message that Proxy's private key can decrypt.
The trivial implementation of this is for Alice to share her private key with Proxy, so he can decrypt the message, and re-encrypt it under Bob's public key.
This implementation clearly fails our constraints, since Proxy both gains access to Alice's private key, and can read the message.
The proxy re-encryption implementation that meets our constraints, is one by Ateniese, Fu, Green, and Hohenberger. 
\cite{afgh}sensible
We'll refer to that implementation as AFGH; we built our Go package based on this implementation.
\cite{noauthor_etclabpre_nodate}

AFGH is an improvement on a few earlier proxy re-encryption models.
Mambo and Okamoto first introduced decryption ability delegation as a way of increasing efficiency over the alternatives at the time.
\cite{mambo_okamoto}
Alternatives at the time were "decrypt-and-then-encrypt" approaches, as described by the AFGH authors.
\cite{afgh}
These would fail our conditions, since they'd allow Proxy to decrypt and read the plaintext, in our example, and Mambo and Okamoto's efficiency improvements wouldn't increase the security guarantees of that. 

Another variation of proxy re-encryption came from Blaze, Bleumer, and Strauss (BBS), and was called "atomic proxy cryptography".
\cite{bbs}
\cite{afgh}
With atomic proxy cryptography, a semi-trusted proxy (Proxy, in our example) can re-encrypt messages (from being readable by Alice to being readable by Bob). 
There are two main limitations that make the proxy only "semi-trusted".
First, it is bidirectional, meaning Proxy can both re-encrypt messages encrypted under Alice's public key into messages that Bob can decrypt, and vice-versa.
In the Samba case, this is an unnecessary feature, and potentially a vulnerability.
As we'll discuss in section \ref{sec:samba}, messages will always be encrypted to Alice, the initial replica of a given FaaS function, re-encrypted by Proxy, the FaaS provider, and sent to Bob, one of potentially many replicas of Alice.
Second, the proxy in BBS can create the tools needed to re-encrypt between Alice and Bob without consent from either Alice or Bob.
An eventual goal of Samba is to exclude the cloud provider from the trust model, by relying on hardware-based trusted execution environments, so we can't allow the function orchestrator the ability do do such things.
Despite these limitations, BBS provides a solid foundation for removing some trust from the proxy, which AFGH builds upon.
\cite{afgh}
\cite{bbs}

Dodis and Ivan (DI) solve both of BBS's drawbacks with their proxy re-encryption implementation, but introduce new drawbacks as well.
\cite{afgh}
\cite{ivan_dodis}
DI works by Alice splitting her private key and giving a portion to both Proxy and Bob.
This means that messages aren't re-encrypted per se, but that Proxy partially decrypts the message, and Bob can finish the job.
One obvious drawback is that if Proxy and Bob collude, Proxy can decrypt and read the messages.
Also, this requires storing extra key material for everyone whose messages can be proxy re-encrypted to you, which would be a problem at scale, and run into the key distribution problem.

There have been other proxy re-encryption methods, with various strengths and drawbacks, but AFGH is mainly a fusion of BBS and DI.
\cite{afgh}
\cite{lidong_zhou_distributed_2005}
\cite{markus}
I'll highlight some of the guarantees of AFGH that are most important to Samba's operation.
AFGH guarantees uni-directionality, or that Proxy delegating a message from Alice to Bob doesn't allow the same to happen from Bob to Alice.
It also guarantees "proxy invisibility", meaning that Bob has no idea if he is the original function or a replica, which is good since the function code itself will be identical.
AFGH, as well as BBS and DI, as a matter of fact, guarantees that nodes can periodically switch out their public-private key pairs such that previously generated re-encryption key material will no longer work, but new material can still be generated.

One feature of AFGH that could be seen as a downside in our implementation is "original access," meaning that Alice can decrypt ciphertexts that were originally meant for her, and now re-encrypted to Bob.
In Samba, all functions are replicas equal to the best of our ability, so ideally a message in any encryption state would only be decryptable by one replica.
AFGH doesn't allow for this, but it's more of a loose end than a serious security flaw for Samba, since each message will only ever be sent from the FaaS provider to exactly one function replica. 
More on this in \ref{sec:samba}.

Also, (1) encrypting a message to Alice, and (2) encrypting a message to Alice that Proxy will be able to re-encrypt, require slightly different algorithms. 
This is important to note in implementation.


\subsection{Compiler Optimizations for Cryptography}
\label{sec:optimization_background}

Cryptographic operations are some of the most expensive operations in modern computing, in both runtime and resource utilization.
Performance should always be a significant consideration when extending a preexisting system with a cryptographic scheme to enhance security.
If performance isn't considered, users and companies in the real world aren't likely to adopt the change, no matter how secure. Certain scheme-specific as well as general compiler optimizations can significantly reduce the overhead in cryptosystems.
