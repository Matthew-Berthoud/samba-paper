\section{Background \& Motivation}
\label{sec:background}

\textbf{adwait}

SAMBA builds upon a number of technologies and concepts in the cloud security space.

\subsection{Trusted Execution Environments}
A Trusted Execution Environment (TEE) is a secure area within a processor that ensures the confidentiality, integrity, and isolation of sensitive code and data.
By separating secure operations from the rest of the system, TEEs protect against both software and hardware attacks, making them essential for applications requiring high trust. 
TEEs also support remote attestation, enabling them to prove to external entities that they are running untampered code in a protected environment.
Google's Project Oak leverages TEEs and the DICE protocol to perform a "measured boot" of the Oak Restricted Kernel.
This means that each stage of the boot process measures (computes the hash of) the following stage, adding them to an attestation record.
We extend this attestation to attest between functions in SAMBA.

AMD SEV-SNP (Secure Encrypted Virtualization - Secure Nested Paging) extends the concept of TEEs to virtualized environments, particularly in cloud computing.
It encrypts each virtual machine's memory with unique hardware-managed keys, ensuring data confidentiality even if the host system or hypervisor is compromised.
SEV-SNP also protects memory integrity by preventing unauthorized modifications and enforces strong isolation between VMs.

\subsection{Function as a Service}
Function as a Service (FaaS) is a cloud computing model that enables developers to deploy and execute individual functions or pieces of code without managing the underlying infrastructure.
These functions are event-driven and run in stateless containers, automatically scaling up or down based on demand, according to the policy of the orchestrator.
FaaS eliminates the need for developers to provision and managing servers, allowing them to focus on writing code while the cloud provider handles resource allocation, availability, and execution.
Popular FaaS platforms include AWS Lambda, Google Cloud Functions, and Azure Functions.
Open and partially open source FaaS platforms discussed in this paper include OpenFaaS, OpenWhisk, and Open Function.

\subsection{Asymmetric Cryptography}
Asymmetric cryptography, also known as public key cryptography, is a cryptographic system that uses a pair of keys: a public key and a secret key.
The public key is shared openly and used for encrypting messages or verifying digital signatures, while the secret key is kept secret and used for decrypting messages or creating digital signatures.
This key pair enables secure communication without the need to share a secret key beforehand.
In SAMBA, public and secret keys are derived from the AMD SEV-SNP hardware, but are specific to each VM.

\subsection{Proxy Re-encryption}
Proxy re-encryption (PRE) is a cryptographic technique that allows transforming ciphertext encrypted under one public key into ciphertext encrypted under a different public key, without revealing the underlying plaintext or requiring access to the private keys.
This is achieved using a re-encryption token, generated by the original data owner, using their private key, and the public key of the destination user they want to re-encrypt to.
That token and the original ciphertext can be sent to the destination user who can re-encrypt the data using the token, and then decrypt it with their private key.
SAMBA applies PRE to FaaS, since auto-scaling behavior means that the original instance of a function may need to re-encrypt data to a scaled-up replica.

\subsection{Aggregate Signatures}
Aggregate signatures are a cryptographic method that combines multiple digital signatures from different signers into a single compact signature, which can be verified collectively.
This technique reduces the overall size of signatures and improves efficiency while maintaining the ability to verify that each signer endorsed their respective message.
SAMBA implements this to verify the path that function data took in a function chain.

\textbf{herwig}

\parhead{Confidential computing.}
%
\emph{Confidential computing} protects data in use by processing it within a
hardware TEE, isolating it from unauthorized access or modification.
%
This proposal focuses on the latest generation of TEEs---specifically AMD
SEV-SNP~\cite{amd-sev_snp}---which encrypts the memory of an entire guest VM to
create \emph{confidential VMs}.
%
% (the Versioned Chip Endorsement Key, or VCEK) 
A critical feature of AMD SEV-SNP (and all TEEs) is \emph{remote attestation}:
the trusted hardware measures (computes a hash of) the VM workload, and a
unique hardware key signs this initial state, producing an \emph{attestation
report}.
%
Thus, AMD serves as the root of trust, eliminating the need to trust the server
owner, while customers can retrieve the attestation report to verify that the
correct software is running within the confidential VM\@.
%
To allow an attestation to bind a runtime value, the confidential VM can
include a small amount of \emph{user data} in the signed report.
%
%
%AMD also provides certificate authority servers that can issue a VCEK
%certificate by signing the corresponding hardware key.


\parhead{Proxy re-encryption.}
%
% https://www.cs.jhu.edu/~susan/600.641/scribes/lecture17.pdf
%
\emph{Proxy re-encryption} is a cryptographic scheme that allows an untrusted
proxy to convert a ciphertext encrypted under Alice's public key into a
ciphertext that Bob can decrypt with his secret key, without learning the
underlying plaintext.
%
At a high-level, Alice and Bob construct a public \emph{re-encryption key}
$RK_{\text{Alice}\rightarrow\text{Bob}}$ that
the proxy uses to re-encrypt the ciphertext from Alice (the \emph{delegator}) to Bob
(the \emph{delegatee}).
%
In 1998, Blaze, Bleumer, \& Strauss~\cite{98-eurocrypt-proxy_cryptography}
designed the first proxy re-encryption construction based on the ElGamal
encryption system~\cite{85-toit-elgamal}.
%
Shortly thereafter, Dodis and Ivan~\cite{03-ndss-proxy_cryptography_revisited}
developed a unidirectional variant, and later Ateniese et
al.~\cite{05-ndss-improved_proxy_reencryption} applied bilinear
maps~\cite{01-crypto-ibe_weil_pairing} (and specifically BLS
signatures~\cite{03-eurocrypt-aggregate_signatures_bilinear_maps}) to develop
schemes that did not require interaction between the delegator and delegatee.
%
Since then, numerous works have explored features like multiple
re-encryptions~\cite{17-tops-fast_proxy_re_encryption} and
revocation~\cite{12-crypto-dynamic_credentials_and_delegation_for_abe}, and
security properties like chosen-ciphertext
resistance~\cite{07-ccs-cca_proxy_re_encryption} and
unlinkability of ciphertexts~\cite{19-acisp-pcs_proxy_reencryption}.


\subsection{Threat Model}
\label{sec:threat-model}

Our system has three parties: the \emph{cloud provider}, the \emph{function
providers}, and \emph{external attackers}.
%
A function chain may contain functions from multiple providers.
%
For any given function provider, the potential adversaries
are the other function providers in the chain, the cloud provider, and
external attackers.
%
The goal of an adversary is to learn the inputs or outputs of a (peer)
function, modify these inputs or outputs, or modify the sequence of functions
in the chain (e.g., to insert a function that sends data to an
adversary-controlled log).
%
A function provider can submit any function to the chain, including a
malicious function that tries to leak data or subvert the cloud
provider.
%
We assume that functions may contain bugs that unintentionally leak
data or expose the function to exploitation.
%
We assume an adversary cannot breach the security of confidential VMs; we trust
the system software in the VM, and consider side-channel attacks out-of-scope.
%
%Since the cloud provider can trivially deny service, we do not guarantee
%availability.


\subsection{Goals}
\label{sec:goals}
\textbf{NOTHING HERE}

\textbf{adwait "Overview" section}
% Overview of Approach (a nice and accessible ``English'' description of
% your approach). Don't forget a niche high-level figure. Our sample
% high-level figure is shown in Figure~\ref{fig:overview}.

% There is sometimes a background section before the overview section. In
% general, you want to try to get your high level figure somewhere between
% pages 2 and 4. It is generally bad to have a figure on the first page
% (but was unavoidable in this sample).

% You may need to move this \begin{figure} ... \end{figure} block around
% in the document to place it in a logical spot in the paper. In
% general, get the figure on the same page as the prose that refers to
% it.
% \begin{figure}[t]
%   \centering
%   \includegraphics[width=3in]{figs/overview}
%   \caption{A high-level architecture of our approach}
%   \label{fig:overview}
% \end{figure}


Our approach consists of two main goals:
\begin{enumerate}
  \item Enabling encryption between functions even in the case of auto-scaling
  \item Extending the attestation goals of Project Oak to cover multi-function workflows
\end{enumerate}

\subsection{Encryption Under Auto-scaling}

Our first goal will be achieved by implementing support for proxy re-encryption within the runtime of the VMs that get scaled by the FaaS orchestrator. The following example explains how this works.
Say function $A$ is passing data to function $B$.
If we knew for a fact that there would only be one instance of function $B$, we could use $B$'s public key to encrypt the data.
Then, when the encrypted data arrives at $B$, they could decrypt it with their private key.

Function as a Service functions add a wrinkle to this simple asymmetric encryption key encryption, due to their autoscaling behavior.
Public and secret keys are bound uniquely to individual Oak Restricted Kernel VMs.
Since only one instance of each function runs in each VM, a messsage encrypted to one replica of a function will not be readable by another replica of that same function.
We assume that all chained functions, in our example function $A$, believe they are sending data to the "original" replica of the recipient function, say $B_0$. 
When the function orchestration framework recieves this request, however, if load balancing has occured, chances are they will be disbatching that request to a replica function, some $B_i$.
Since $B_i$ can't read the message from $A$ without access to $B_0$'s secret key, re-enctyption must occur.

In our solution, the moment any replica $B_i$ is created to handle additional load, a \textit{proxy re-encryption token} request is sent to the original function, $B_0$.
The request contains some indication that it's a \textit{proxy re-encryption token} request, as well as $B_i$'s public key.
Using that $B_i$'s public key and $B_0$'s secret key, $B_0$ generates a proxy re-encryption token, with the method described in Section~\ref{sec:background}. 
That token is sent back to the orchestrator, who provides it to $B_i$ on startup.
Now, whenever the orchestrator is load balancing and wants to assign a workload to $B_i$, it can directly send ciphertext that was encrypted for $B_0$, without added overhead.
Upon recieving the data, $B_i$ can first re-encrypt it with the $B_0,B_i$ token, and then decrypt it with their ($B_i$'s) private key.

This one additional crypto operation is a necessary sacrifice to keep the efficiency gains of auto-scaling, while adding confidentiality from encryption.
We chose to perform the re-encryption step in the recipient replica $B_i$ as opposed to the orchestrator.
In theory, for each request, either of those approaches would take the same amount of time.
However, in the real context of a high-load system with more than one workload in need of allocation, offloading the additional step to the replica frees up the orchestrator to continue handling requests.


\subsection{Function Chain Attestation}

Our second goal will be achieved by implementing certificate chain validation within the function VM runtime.
The Oak Restricted Kernel already performs a "measured boot" where each stage of the VM's startup process "measures" the next, attesting to its correctness.
They do this according to the DICE protocol.
This makes it so that only Stage 0 of that process has to be trusted, as well as the hardware, since any interfering with other parts of the boot will be recorded, and recognized when verifying the measurement.

We extend this idea by creating a certificate chain, as explained in Section~\ref{sec:background}, of the callers and callees in each fucntion chain.
We extend the Oak Restricted Kernel runtime to that during the booting of a function, this chain is checked against the expected route.
From there, the current workload is hashed, signed, and added onto the chain.
The next function, or the end user will be able to verify in the same way.

\subsection{Threat Model}

There are three main parties at play in our system. The cloud provider, the function providers (users), and external attackers.
The possible adversaries for any given user are other users in the same chain of functions, the cloud provider who's hosting the user's function, and external attackers.
The goal of other users could be to pass fraudulent data into the function in question, change the order of function execution, or more generally read function input/output data they aren't authorized to read.
The goal of the cloud provider could be to boot the function in such a way that it logs all data back to them, and protecting against this is in scope.
The goal of external attackers would be similar to that of other users, but likely with less explicit baseline access to the function provider.
Our Trusted Computing Base (TCB) includes the AMD SEV-SNP hardware, and the Oak Restricted Kernel software.
We put no trust in the cloud provider, other functions in the chain, or in any centralized keystore or log.
We do assume side-channel attacks are out of scope, but preventing these while maintaining SAMBA's guarantes could be an interesting area of future research, discussed in Section~\ref{sec:discussion}.

